-Discuss the purpose of this database in the context of the startup, Sparkify, and their analytical goals

This database contains tables that are related to each other in a star schema model, with one fact table (songplays) and several dimension tables (songs, artists, users, and time). As with most implementations of a star schema, this facilitates simple, denormalized queries and fast aggregations. For our purposes as a music streaming startup, this data model would help analysts execute queries without too many joins and support easy aggregations concerning information about users, time, artists, songs, or songplays (like if you wanted to count the number of times a song was played by a user in the songplays table). This database would be able to provide queriers with information about the intersections of demographic data (gender), which artists are being played, and the songs/ artists on the platform, for example. This would help them make informed business decisions about changes and additions to the service.

-State and justify your database schema design and ETL pipeline

As stated above, my database schema design consists of one fact table and four dimension tables. These are created when create_tables.py is run (and we connect to our database), which takes the query strings from sql_queries.py and drops (if exists) any created tables and then creates them again in our instance of postgres. After that, etl.py should be run, which takes the raw json file data, converts it into a pandas dataframe, and then executes multiple insert statements that posit the records into each respective sql table. This is an efficient pipeline because we insert as much data as we can at a time by executing insert statements multiple times throughout each log or song json file iteration. Etl.ipynb is a jupyter notebook walking the user through the testing of inserting a single json file's data into the respective tables, while test.ipynb contains test queries to run on the database tables after create_tables.py and etl.py have been run